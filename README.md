# BuildStory.Agents

**Autonomous AI agents for real-time landing page optimization**

BuildStory.Agents is a Next.js application where autonomous AI agents generate, test, and optimize landing pages in real-time using multi-armed bandits and persona-based targeting.

## ğŸ¯ What It Does

- **Persona Classification**: Automatically detects if visitors are developers, investors, or end users
- **Dynamic Content Generation**: AI agents create and optimize sections based on visitor persona
- **Multi-Armed Bandit Testing**: Thompson sampling automatically finds best-performing variants
- **Real-Time Adaptation**: Pages adapt instantly based on visitor behavior and conversion data
- **Brand Consistency**: Brand guardian ensures tone and style consistency across all variants

## ğŸ—ï¸ Architecture

### Agents
- **PersonaAgent**: Fast persona classification based on UTM params, referrer, device type
- **SectionAgent**: Generates optimized content for each section type (hero, problem, solution, etc.)
- **BrandGuardian**: Validates content against brand guidelines and tone
- **Strategist**: Uses Thompson sampling to choose optimal variants
- **DataStoryteller**: Converts user events into social proof and testimonials

### Multi-Armed Bandit
- Thompson sampling for variant selection
- Beta distribution for conversion rate estimation
- Automatic reward tracking and parameter updates
- Per-section, per-persona optimization

### Tech Stack
- **Framework**: Next.js 16 with App Router
- **Database**: Supabase (PostgreSQL)
- **Caching**: Redis/Upstash (optional)
- **AI**: OpenAI GPT-4 for content generation
- **Animation**: Framer Motion
- **Styling**: Tailwind CSS
- **Types**: TypeScript with Zod validation

## ğŸš€ Quick Start

### 1. Prerequisites
- [Bun](https://bun.sh) (primary package manager and runtime)
- Node.js 20+ optional (for some tooling)
- Supabase account
- OpenAI API key

### 2. Installation
```bash
git clone <your-repo>
cd buildstory-agents
bun install
```

### 3. Database Setup
1. Create a new Supabase project
2. Run the SQL from `database/schema.sql` in your Supabase SQL editor
3. Copy your Supabase URL and anon key

### 4. Environment Configuration
Create a `.env.local` file in the project root with the required secrets:
```env
OPENAI_API_KEY=sk-your-openai-key-here
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-supabase-anon-key
```

- **Required**: `OPENAI_API_KEY`, `SUPABASE_URL`, `SUPABASE_ANON_KEY`. The app throws a clear error at startup if Supabase vars are missing, and on first LLM use if `OPENAI_API_KEY` is missing.
- **Optional**: `OPENAI_MODEL` â€” OpenAI chat model for content generation (default: `gpt-4o`). Set to e.g. `gpt-4-turbo` if you prefer.
- **Optional (rate limiting)**: `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` â€” when set, rewrite and track APIs use Redis for rate limits across instances; otherwise in-memory limits are used.

The app expects these variables in both the Next.js runtime and the Supabase maintenance scripts (`node update_schema.js`). No example file is shipped, so copy the snippet above directly.

### 5. Run Development Server
```bash
bun dev
```

Visit `http://localhost:3000` to see the application.

### 6. Database Helpers (Optional)
Run `node update_schema.js` to ensure the `events` table accepts the latest persona set (`athlete`, `commuter`, `outdoor`, `family`). This script calls the Supabase `exec_sql` RPC, which should be defined as:
```sql
create or replace function exec_sql(sql text)
returns void
language plpgsql
security definer set search_path = public
as $$
begin
  execute sql;
end;
$$;

grant execute on function exec_sql(text) to anon, authenticated, service_role;
```
Run the grant statements that match your project policies before executing the script.

## ğŸ“ Usage

### Creating a Story
1. Fill out the product brief (describe your product in 2-3 sentences)
2. Set brand name and tone (professional, friendly, authoritative, conversational)
3. Choose primary color
4. Click "Generate Landing Page"

### Viewing Generated Landing Page
- Visit `/s/[storyId]` to see your generated landing page
- The page adapts based on your detected persona (dev/investor/user)
- Append `?persona=athlete|commuter|outdoor|family` to the URL or use the persona bar in the top-right to manually switch personas
- All interactions are tracked for optimization

### Real-Time Optimization
- Each section has multiple variants generated by AI agents
- The strategist uses Thompson sampling to show the best-performing variant
- Conversion events (CTA clicks) update the bandit parameters stored in `bandit_state`
- Pages improve automatically as more visitors interact

## ğŸ›ï¸ Database Schema

### Tables
- `stories`: Basic story information and brand settings
- `storyboards`: Generated landing page versions per persona
- `bandit_state`: Multi-armed bandit parameters (alpha, beta) per variant
- `events`: User interaction tracking (views, clicks, scrolls, etc.)

### Key Relationships
- Stories have multiple storyboards (one per persona)
- Each section can have multiple variants tracked in bandit_state
- All user interactions are logged as events for analysis

## ğŸ”§ API Endpoints

### POST /api/story
Create a new story with AI-generated content
```json
{
  "brief": "Product description",
  "tone": "professional",
  "brandName": "Your Brand",
  "palette": ["#3b82f6", "#1e40af", "#64748b"]
}
```

### POST /api/rewrite
Optimize a specific section or request a fresh variant
```json
{
  "storyId": "uuid",
  "sectionKey": "hero",
  "goal": "conversion",
  "optimize": true
}
```

### POST /api/track
Track user events
```json
{
  "storyId": "uuid",
  "sectionKey": "hero",
  "variantHash": "abc123",
  "event": "ctaClick",
  "meta": {"ctaIndex": 0}
}
```

### GET /api/debug
Environment, Supabase, OpenAI, and persona health check

### GET /s/[storyId]
Server-side rendered landing page with agent optimizations (supports `?persona=` overrides)

## ğŸ“Š Metrics and Evaluation

The system collects detailed metrics to monitor agent performance and optimize content generation. Metrics are available via the `metrics` utility.

### Core Metrics

1. **Agent Operations**
   - Tracks success/failure of agent operations
   - Includes operation type, duration, and status
   - Example: `agent_operation { agent_type: 'PersonaAgent', operation: 'classify', status: 'success', duration_ms: 125 }`

2. **Latency**
   - Measures processing time for agent operations
   - Helps identify performance bottlenecks
   - Example: `agent_metrics { type: 'latency', agent_type: 'SectionAgent', operation: 'generate', value: 320 }`

3. **Errors**
   - Tracks errors by type and agent
   - Includes error messages for debugging
   - Example: `agent_metrics { type: 'error', agent_type: 'BrandGuardian', error_type: 'ValidationError', operation: 'validate' }`

4. **Bandit Performance**
   - Tracks variant selection and conversion rates
   - Helps optimize content performance

### Accessing Metrics

```typescript
import { metrics } from './lib/server/metrics';

// Get all metrics
const metricsData = metrics.getMetrics();
console.log(metricsData);

// Example: Get error count by type
const errorCount = metricsData.metrics
  .filter(m => m.name === 'error_count')
  .reduce((sum, m) => sum + (m.values['agent_type=PersonaAgent,error_type=APIError'] || 0), 0);
```

### Using withMetrics

Wrap agent operations to automatically track metrics:

```typescript
import { withMetrics } from './lib/server/metrics';

async function processRequest() {
  return withMetrics('MyAgent', 'processRequest', async () => {
    // Your agent logic here
    const result = await someAsyncOperation();
    return result;
  }, { requestId: 'req-123' }); // Optional metadata
}
```

### Monitoring and Alerting

1. **Performance Monitoring**
   - Set up alerts for high latency operations
   - Monitor error rates by agent type
   - Track conversion rates for different variants

2. **Example Alerts**
   - Alert if error rate exceeds 5% for any agent
   - Notify if average latency exceeds 1s
   - Track conversion rate drops

### Testing

Unit tests for metrics collection are available in `src/lib/__tests__/agentMetrics.test.ts`.

To run tests:
```bash
npx vitest run
```

## ğŸ¨ Section Types

### Hero
- Headline, subheading, CTA buttons
- Demo idea suggestion

### Bullets (Problem)
- List of pain points
- Visual bullet points with icons

### Steps (Solution)
- Numbered workflow steps
- Sequential flow design

### Quotes (Social Proof)
- Customer testimonials
- Role/company attribution

### Tiers (Pricing)
- Pricing plans with features
- Popular tier highlighting

### QnA (FAQ)
- Expandable question/answer pairs
- Common objections addressed

## ğŸ§  AI Prompts

The system uses carefully crafted prompts for different agents:

- **Planner**: Creates complete storyboards from brief + persona
- **Rewriter**: Optimizes individual sections for specific goals
- **Brand Guardian**: Ensures consistency with brand guidelines

All LLM calls use the model from `OPENAI_MODEL` (default: `gpt-4o`) and require `OPENAI_API_KEY` to be present.

Prompts include persona targeting, tone enforcement, and structural constraints.

## ğŸ“Š Analytics & Optimization

### Event Tracking
- Page views and dwell time
- Scroll depth and engagement
- CTA clicks and conversions
- Persona polling and switching

### Bandit Metrics
- Conversion rates per variant
- Confidence intervals
- Total trials and regret
- Performance dashboards (coming soon)

### Real-Time Updates
- Thompson sampling for variant selection
- Automatic parameter updates on conversions
- Live adaptation to visitor behavior

## ğŸ”’ Security & Guidelines

### Content Safety
- PII detection and blocking
- Profanity filtering
- Unverifiable claims prevention
- Brand guideline enforcement

### Rate Limiting
- API endpoints protected
- Per-IP request limits
- Graceful degradation

## ğŸš€ Deployment

### Vercel (Recommended)
1. Connect your GitHub repository
2. Add environment variables in Vercel dashboard
3. Deploy automatically on push

### Other Platforms
- Ensure Node.js 18+ support
- Configure environment variables
- Set up database connection

## ğŸ“ˆ Performance

### Optimization Strategies
- Edge runtime for fast response times
- ISR with 60-second revalidation
- Efficient database queries with indexes
- Client-side caching for repeated requests

### Monitoring
- Real-time conversion tracking
- Bandit performance metrics
- Error monitoring and alerts
- Performance analytics

## ğŸ› ï¸ Development

### Project Structure
```
src/
â”œâ”€â”€ app/                   # Next.js App Router
â”‚   â”œâ”€â”€ (site)/s/[id]/    # Dynamic story pages
â”‚   â”œâ”€â”€ api/              # API endpoints
â”‚   â””â”€â”€ page.tsx          # Home page
â”œâ”€â”€ components/           # UI components
â”‚   â””â”€â”€ sections/         # Landing page sections
â”œâ”€â”€ lib/                  # Shared (types, validation, client-safe)
â”‚   â”œâ”€â”€ storyboard.ts    # Types and validation
â”‚   â”œâ”€â”€ personas.ts      # Persona types and themes
â”‚   â”œâ”€â”€ tracking.ts      # Client-side event tracking
â”‚   â””â”€â”€ utils.ts         # Shared utilities
â”œâ”€â”€ lib/server/           # Server-only (never import from client)
â”‚   â”œâ”€â”€ agents/          # AI agents
â”‚   â”œâ”€â”€ database.ts      # Database operations
â”‚   â”œâ”€â”€ bandit.ts        # Multi-armed bandit
â”‚   â”œâ”€â”€ config.ts        # Env/config
â”‚   â””â”€â”€ metrics.ts       # Agent metrics
â””â”€â”€ database/            # SQL schema
```

### Adding New Agents
1. Create agent file in `lib/server/agents/`
2. Implement the `propose(context, section)` interface
3. Add to strategist workflow
4. Update API endpoints as needed

### Developer Tooling
- **bun lint**: Type-checks with `tsc --noEmit` then runs `next lint`
- **bun run format**: Applies Biome formatting defaults

### Adding New Section Types
1. Add type to Zod schema in `storyboard.ts`
2. Create React component in `components/sections/`
3. Update section rendering logic
4. Add agent prompts for the new type

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ†˜ Troubleshooting

### Common Issues
- **Database connection**: Check Supabase URL and key
- **LLM generation**: Verify OpenAI API key and quotas
- **Persona detection**: May need manual override via URL params
- **Bandit convergence**: Requires sufficient traffic for optimization

### Debug Mode
Set `NODE_ENV=development` for verbose logging and error details.

---

**BuildStory.Agents** - Where AI meets conversion optimization ğŸš€
